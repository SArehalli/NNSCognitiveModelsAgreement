{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d96f22",
   "metadata": {},
   "source": [
    "Trying a causual intervention strategy to determine how much the representations built for CCG supertagging are used in language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b523862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "model_path = \"../CCGMultitask/models/augment/augment_.50_0_sgd_continue\"\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54814f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "sys.path.insert(0, \"../CCGMultitask/\")\n",
    "from model import MultiTaskModel\n",
    "from train_augment import evaluate_lm, evaluate_ccg\n",
    "from train_joint import evaluate_joint\n",
    "from data import joint_tag_lm, augment_tag_lm, AugmentDataset, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302514fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path + \".w2idx\", \"rb\") as w2idx_f:\n",
    "    w2idx = pickle.load(w2idx_f)\n",
    "    \n",
    "vocab = {i:w for (w, i) in w2idx.items()}\n",
    "    \n",
    "with open(model_path + \".c2idx\", \"rb\") as c2idx_f:\n",
    "    c2idx = pickle.load(c2idx_f)\n",
    "    \n",
    "categories = {i:c for (c, i) in c2idx.items()}\n",
    "    \n",
    "model = MultiTaskModel(len(w2idx.keys()), 650, 650, [len(w2idx.keys()), len(c2idx.keys())], 2)\n",
    "model.load_state_dict(torch.load(model_path + \".pt\", map_location = torch.device(\"cpu\")))\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "if cuda: model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = joint_tag_lm(\"../CCGMultitask/data/ccg_supertags/ccg.23.common\", \n",
    "                         \"../CCGMultitask/data/ccg_supertags/categories\", 35, w2idx=w2idx)\n",
    "test_sampler = BatchSampler(test_data, 10)\n",
    "test_loader = DataLoader(test_data, batch_sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([w2idx[w.lower()] for w in \"<eos> The key to the cabinet\".split()])\n",
    "\n",
    "if cuda: input = input.cuda()\n",
    "    \n",
    "hidden = model.init_hidden(1)\n",
    "\n",
    "out, hidden = model.lstm(input.view(-1, 1), hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b00a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = out.squeeze()[-1]\n",
    "\n",
    "# Generate outputs\n",
    "\n",
    "logits = [decoder(state) for decoder in model.decoders]\n",
    "\n",
    "lm_logits, ccg_logits = logits\n",
    "\n",
    "lm_top5 = lm_logits.squeeze().topk(5)\n",
    "for idx, p in zip(lm_top5.indices, lm_top5.values):\n",
    "    print(\"{}:\\t{}\".format(vocab[idx.item()], p))\n",
    "    \n",
    "print(\"---\")\n",
    "ccg_top5 = ccg_logits.squeeze().topk(5)\n",
    "for idx, p in zip(ccg_top5.indices, ccg_top5.values):\n",
    "    print(\"{}:\\t{}\".format(categories[idx.item()], p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff5d3cf",
   "metadata": {},
   "source": [
    "Ablate individual \"neurons\" in the final layer. (finding highly localized syntactic neurons used for one task but not the other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd14c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_losses = {}\n",
    "ccg_losses = {}\n",
    "\n",
    "loss_f = nn.NLLLoss()\n",
    "\n",
    "hidden = model.init_hidden(10)\n",
    "with torch.no_grad():\n",
    "    for (input, target_lm, target_ccg) in tqdm.tqdm(test_loader):\n",
    "        if cuda:\n",
    "            input = input.cuda()\n",
    "            target_lm = target_lm.cuda()\n",
    "            target_ccg = target_ccg.cuda()\n",
    "                \n",
    "        input = input.transpose(0,1).contiguous()\n",
    "        target_lm = target_lm.transpose(0,1).contiguous()\n",
    "        target_ccg = target_ccg.transpose(0,1).contiguous()\n",
    "        \n",
    "        state, hidden = model.lstm(input, hidden)\n",
    "        for unit_idx in range(state.shape[-1]):\n",
    "            state_ = state.clone().detach()\n",
    "            state_[:, :, unit_idx] = 0 #ablate\n",
    "            \n",
    "            lm_probs, ccg_probs = [decoder(state_) for decoder in model.decoders]\n",
    "            \n",
    "            lm_losses[unit_idx] = lm_losses.get(unit_idx, 0) + loss_f(lm_probs, target_lm.view(-1)).item()\n",
    "            ccg_losses[unit_idx] = ccg_losses.get(unit_idx, 0) + loss_f(ccg_probs, target_ccg.view(-1)).item()\n",
    "        \n",
    "        # unablated\n",
    "        lm_probs, ccg_probs = [decoder(state) for decoder in model.decoders]\n",
    "            \n",
    "        lm_losses[-1] = lm_losses.get(-1, 0) + loss_f(lm_probs, target_lm.view(-1)).item()\n",
    "        ccg_losses[-1] = ccg_losses.get(-1, 0) + loss_f(ccg_probs, target_ccg.view(-1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed10850",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ablated_rep_lm.loss\", \"wb\") as lm_loss_f:\n",
    "    pickle.dump(lm_losses, lm_loss_f)\n",
    "    \n",
    "with open(\"./ablated_rep_ccg.loss\", \"wb\") as ccg_loss_f:\n",
    "    pickle.dump(ccg_losses, ccg_loss_f)\n",
    "    \n",
    "print(len(lm_losses.items()))\n",
    "\n",
    "loss_by_ablation = {i:(lm_losses[i]/len(test_loader), ccg_losses[i]/len(test_loader)) for i in range(len(lm_losses.items()))}\n",
    "\n",
    "with open(\"./ablated_rep.loss\", \"wb\") as loss_f:\n",
    "    pickle.dump(loss_by_ablation, loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3151be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ablated_rep_lm.loss\", \"rb\") as lm_loss_f:\n",
    "    lm_losses = pickle.load(lm_loss_f)\n",
    "    \n",
    "with open(\"./ablated_rep_ccg.loss\", \"rb\") as ccg_loss_f:\n",
    "    ccg_losses = pickle.load(ccg_loss_f)\n",
    "\n",
    "loss_by_ablation = {(i-1):(lm_losses[i-1]/len(test_loader), ccg_losses[i-1]/len(test_loader)) for i in range(len(lm_losses.items()))}\n",
    "\n",
    "print(loss_by_ablation)\n",
    "\n",
    "csv_losses = []\n",
    "\n",
    "for i, (lm_loss, ccg_loss) in loss_by_ablation.items():\n",
    "    csv_losses.append({\"ablated_dim\": i,\n",
    "                       \"lm_loss\": lm_loss,\n",
    "                       \"ccg_loss\": ccg_loss})\n",
    "    \n",
    "import csv\n",
    "\n",
    "with open(\"ablated_rep.csv\", \"w\") as csv_out_f:\n",
    "    writer = csv.DictWriter(csv_out_f, fieldnames = csv_losses[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(csv_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c9565",
   "metadata": {},
   "source": [
    "Use a non-iterated version of iNLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b581ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lmccg_path = \"../CCGMultitask/models/augment/augment_.50_0_sgd_continue\"\n",
    "model_lmonly_path = \"../CCGMultitask/models/augment/augment_1.00_0_sgd_continue\"\n",
    "model_ccgprobe_path = \"./models/augment_1.00_0_sgd_continue_ccgfrozen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c382ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    with open(model_path + \".w2idx\", \"rb\") as w2idx_f:\n",
    "        w2idx = pickle.load(w2idx_f)\n",
    "    \n",
    "    vocab = {i:w for (w, i) in w2idx.items()}\n",
    "    \n",
    "    with open(model_path + \".c2idx\", \"rb\") as c2idx_f:\n",
    "        c2idx = pickle.load(c2idx_f)\n",
    "    \n",
    "    categories = {i:c for (c, i) in c2idx.items()}\n",
    "    \n",
    "    model = MultiTaskModel(len(w2idx.keys()), 650, 650, [len(w2idx.keys()), len(c2idx.keys())], 2)\n",
    "    model.load_state_dict(torch.load(model_path + \".pt\", map_location = torch.device(\"cpu\")))\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    if cuda: model.cuda()\n",
    "        \n",
    "    return model, w2idx, vocab, c2idx, categories\n",
    "\n",
    "model_lmccg, w2idx_lmccg, vocab_lmccg, c2idx_lmccg, categories_lmccg = load_model(model_lmccg_path)\n",
    "model_lmonly, w2idx_lmonly, vocab_lmonly, c2idx_lmonly, categories_lmonly = load_model(model_lmonly_path)\n",
    "model_ccgprobe, w2idx_ccgprobe, vocab_ccgprobe, c2idx_ccgprobe, categories_ccgprobe = load_model(model_ccgprobe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28446c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_lmccg = joint_tag_lm(\"../CCGMultitask/data/ccg_supertags/ccg.23.common\", \n",
    "                         \"../CCGMultitask/data/ccg_supertags/categories\", 35, w2idx=w2idx_lmccg)\n",
    "test_sampler_lmccg = BatchSampler(test_data_lmccg, 10)\n",
    "test_loader_lmccg = DataLoader(test_data_lmccg, batch_sampler=test_sampler_lmccg)\n",
    "\n",
    "test_data_lmonly = joint_tag_lm(\"../CCGMultitask/data/ccg_supertags/ccg.23.common\", \n",
    "                         \"../CCGMultitask/data/ccg_supertags/categories\", 35, w2idx=w2idx_lmonly)\n",
    "test_sampler_lmonly = BatchSampler(test_data_lmonly, 10)\n",
    "test_loader_lmonly = DataLoader(test_data_lmonly, batch_sampler=test_sampler_lmonly)\n",
    "\n",
    "test_data_ccgprobe = joint_tag_lm(\"../CCGMultitask/data/ccg_supertags/ccg.23.common\", \n",
    "                         \"../CCGMultitask/data/ccg_supertags/categories\", 35, w2idx=w2idx_ccgprobe)\n",
    "test_sampler_ccgprobe = BatchSampler(test_data_ccgprobe, 10)\n",
    "test_loader_ccgprobe = DataLoader(test_data_ccgprobe, batch_sampler=test_sampler_ccgprobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4915bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3007e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "ccg_decoder = model.decoders[1]\n",
    "\n",
    "W = ccg_decoder.linear.weight.detach().cpu().numpy()\n",
    "\n",
    "basis = linalg.null_space(W)\n",
    "\n",
    "P = basis.dot(basis.T)\n",
    "\n",
    "sum(abs(W.dot(P.dot(np.random.rand(650)))) < 1e-5) == 427\n",
    "\n",
    "P = torch.Tensor(P)\n",
    "\n",
    "if cuda: P = P.cuda()\n",
    "\n",
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef93a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_P(weight):\n",
    "    W = weight.detach().cpu().numpy()\n",
    "    basis = linalg.null_space(W)\n",
    "    P = basis.dot(basis.T)\n",
    "\n",
    "    P = torch.Tensor(P)\n",
    "    if cuda: P = P.cuda()\n",
    "        \n",
    "    return P\n",
    "\n",
    "def nsp_losses(model, P, test_loader):\n",
    "    lm_loss = 0\n",
    "    ccg_loss = 0\n",
    "    ccg_correct = 0\n",
    "\n",
    "    nsp_lm_loss = 0\n",
    "    nsp_ccg_loss = 0\n",
    "    nsp_ccg_correct = 0\n",
    "\n",
    "    total_examples = 0\n",
    "    \n",
    "    loss_f = nn.NLLLoss()\n",
    "\n",
    "    hidden = model.init_hidden(10)\n",
    "    with torch.no_grad():\n",
    "        for (input, target_lm, target_ccg) in tqdm.tqdm(test_loader):\n",
    "            if cuda:\n",
    "                input = input.cuda()\n",
    "                target_lm = target_lm.cuda()\n",
    "                target_ccg = target_ccg.cuda()\n",
    "                \n",
    "            input = input.transpose(0,1).contiguous()\n",
    "            target_lm = target_lm.transpose(0,1).contiguous()\n",
    "            target_ccg = target_ccg.transpose(0,1).contiguous()\n",
    "        \n",
    "            state, hidden = model.lstm(input, hidden)\n",
    "            state_ = state.clone().detach()\n",
    "            state_ = torch.matmul(P, state_.view(state_.shape[0], state_.shape[1], state_.shape[2], 1))\n",
    "            state_ = state_.squeeze()\n",
    "\n",
    "            num_examples = len(target_lm.view(-1))\n",
    "            total_examples += num_examples\n",
    "        \n",
    "            nsp_lm_probs, nsp_ccg_probs = [decoder(state_) for decoder in model.decoders]\n",
    "            nsp_lm_loss += num_examples * loss_f(nsp_lm_probs, target_lm.view(-1)).item()\n",
    "            nsp_ccg_loss += num_examples * loss_f(nsp_ccg_probs, target_ccg.view(-1)).item()\n",
    "            nsp_ccg_correct += (nsp_ccg_probs.argmax(dim=1) == target_ccg.view(-1)).sum().item()\n",
    "        \n",
    "            lm_probs, ccg_probs = [decoder(state) for decoder in model.decoders]\n",
    "            lm_loss += num_examples * loss_f(lm_probs, target_lm.view(-1)).item()\n",
    "            ccg_loss += num_examples * loss_f(ccg_probs, target_ccg.view(-1)).item()\n",
    "            ccg_correct += (ccg_probs.argmax(dim=1) == target_ccg.view(-1)).sum().item()\n",
    "        \n",
    "        \n",
    "    lm_loss = lm_loss/total_examples\n",
    "    ccg_loss = ccg_loss/total_examples\n",
    "    ccg_accuracy = ccg_correct/total_examples\n",
    "    \n",
    "    nsp_lm_loss = nsp_lm_loss/total_examples\n",
    "    nsp_ccg_loss = nsp_ccg_loss/total_examples\n",
    "    nsp_ccg_accuracy = nsp_ccg_correct/total_examples\n",
    "    \n",
    "    return lm_loss, ccg_loss, ccg_accuracy, nsp_lm_loss, nsp_ccg_loss, nsp_ccg_accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8017dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6cf18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, _, _, rand_lm_loss, rand_ccg_loss, rand_ccg_accuracy = nsp_losses(model_lmccg, get_P(torch.rand((650, 650))).cuda(), test_loader_lmccg)\n",
    "print(\"no intervention: lm {}, ccg {}/{}\\nintervention: lm {}, ccg {}/{}\\nrandom proj: lm {}, ccg {}/{}\".format(\n",
    "    *nsp_losses(model_lmccg, get_P(model_lmccg.decoders[1].linear.weight), test_loader_lmccg), \n",
    "    rand_lm_loss, rand_ccg_loss, rand_ccg_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"no intervention: lm {}, ccg {}/{}\\nintervention: lm {}, ccg {}/{}\".format(\n",
    "    *nsp_losses(model_lmonly, get_P(model_lmonly.decoders[1].linear.weight), test_loader_lmonly)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86666765",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"no intervention: lm {}, ccg {}/{}\\nintervention: lm {}, ccg {}/{}\".format(\n",
    "    *nsp_losses(model_ccgprobe, get_P(model_ccgprobe.decoders[1].linear.weight), test_loader_ccgprobe)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
